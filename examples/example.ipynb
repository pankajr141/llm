{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-04-07T18:00:53.542598Z","iopub.status.busy":"2025-04-07T18:00:53.542285Z","iopub.status.idle":"2025-04-07T18:00:54.227123Z","shell.execute_reply":"2025-04-07T18:00:54.226052Z","shell.execute_reply.started":"2025-04-07T18:00:53.542557Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'llm'...\n","remote: Enumerating objects: 78, done.\u001b[K\n","remote: Counting objects: 100% (78/78), done.\u001b[K\n","remote: Compressing objects: 100% (54/54), done.\u001b[K\n","remote: Total 78 (delta 36), reused 58 (delta 19), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (78/78), 47.22 KiB | 6.75 MiB/s, done.\n","Resolving deltas: 100% (36/36), done.\n"]}],"source":["!rm -rf llm\n","!git clone https://github.com/pankajr141/llm.git"]},{"cell_type":"markdown","metadata":{},"source":["# Existing Model to be used for retraining"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2025-04-07T18:08:39.888766Z","iopub.status.busy":"2025-04-07T18:08:39.888405Z","iopub.status.idle":"2025-04-07T18:08:40.068224Z","shell.execute_reply":"2025-04-07T18:08:40.066883Z","shell.execute_reply.started":"2025-04-07T18:08:39.888738Z"},"trusted":true},"outputs":[],"source":["!ls /kaggle/input/llm-bhasa"]},{"cell_type":"markdown","metadata":{},"source":["# LLM Training"]},{"cell_type":"markdown","metadata":{},"source":["## Training - Direct through library"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2025-04-07T18:00:54.228824Z","iopub.status.busy":"2025-04-07T18:00:54.228430Z","iopub.status.idle":"2025-04-07T18:00:56.379651Z","shell.execute_reply":"2025-04-07T18:00:56.378904Z","shell.execute_reply.started":"2025-04-07T18:00:54.228787Z"},"trusted":true},"outputs":[],"source":["%%time\n","\n","from llm.bhasa import training\n","model_filepath=\"/kaggle/working/model_and_optimizer.pth\"\n","# training.train(num_epochs=1, eval_freq=100)"]},{"cell_type":"markdown","metadata":{},"source":["## Training - Lets break down\n","\n","Below we will break above single line function into building blocks to have more fine grain control"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2025-04-07T18:15:30.840844Z","iopub.status.busy":"2025-04-07T18:15:30.840503Z","iopub.status.idle":"2025-04-07T18:15:30.845570Z","shell.execute_reply":"2025-04-07T18:15:30.844508Z","shell.execute_reply.started":"2025-04-07T18:15:30.840816Z"},"trusted":true},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'torch'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbhasa\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m data\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"]}],"source":["import os\n","import torch\n","import torch.nn as nn\n","from llm.bhasa import data\n","from llm.bhasa import config\n","from llm.bhasa import model\n","from llm.bhasa import training\n","from llm.bhasa import generator\n","from llm.bhasa import data, dataset\n","from llm.bhasa import tokenizer as tokenizer_lib"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2025-04-07T18:00:56.389854Z","iopub.status.busy":"2025-04-07T18:00:56.389508Z","iopub.status.idle":"2025-04-07T18:00:56.403995Z","shell.execute_reply":"2025-04-07T18:00:56.402988Z","shell.execute_reply.started":"2025-04-07T18:00:56.389816Z"},"trusted":true},"outputs":[],"source":["model_filepath = \"/kaggle/working/model_and_optimizer.pth\"\n","config_train = config.GPT_CONFIG_124M\n","context_len = config_train['context_length']"]},{"cell_type":"markdown","metadata":{},"source":["### Download data"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2025-04-07T18:07:02.430243Z","iopub.status.busy":"2025-04-07T18:07:02.429950Z","iopub.status.idle":"2025-04-07T18:07:45.874147Z","shell.execute_reply":"2025-04-07T18:07:45.873204Z","shell.execute_reply.started":"2025-04-07T18:07:02.430221Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Total Downloaded Books: 72\n","CPU times: user 709 ms, sys: 247 ms, total: 956 ms\n","Wall time: 43.4 s\n"]}],"source":["%%time\n","\n","gutenberg_book_ids = range(100)\n","filepaths = data.download_sample_text(gutenberg_book_ids=gutenberg_book_ids, verbose=False)\n","textdata = data.read_filepaths(filepaths)\n","\n","print(f\"Total Downloaded Books: {len(os.listdir('gutenberg_books'))}\")"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2025-04-07T18:01:40.340333Z","iopub.status.busy":"2025-04-07T18:01:40.340047Z","iopub.status.idle":"2025-04-07T18:01:40.343838Z","shell.execute_reply":"2025-04-07T18:01:40.343204Z","shell.execute_reply.started":"2025-04-07T18:01:40.340307Z"},"trusted":true},"outputs":[],"source":["from llm.bhasa import tokenizer as tokenizer_lib\n","tokenizer = tokenizer_lib.get_tokenizer()"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2025-04-07T18:01:40.345085Z","iopub.status.busy":"2025-04-07T18:01:40.344792Z","iopub.status.idle":"2025-04-07T18:01:45.362874Z","shell.execute_reply":"2025-04-07T18:01:45.361794Z","shell.execute_reply.started":"2025-04-07T18:01:40.345054Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Characters: 36845989\n","Tokens: 10057729\n"]}],"source":["total_characters = len(textdata)                # Number of characters in textdata\n","total_tokens = len(tokenizer.encode(textdata))  # Convert/Encode textdata -> tokens to be passed to LLM\n","print(f\"Characters: {total_characters}\\nTokens: {total_tokens}\")"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2025-04-07T18:01:45.363957Z","iopub.status.busy":"2025-04-07T18:01:45.363712Z","iopub.status.idle":"2025-04-07T18:01:45.437999Z","shell.execute_reply":"2025-04-07T18:01:45.436901Z","shell.execute_reply.started":"2025-04-07T18:01:45.363935Z"},"trusted":true},"outputs":[],"source":["train_data, val_data = training.split_data(textdata, train_ratio=0.70)"]},{"cell_type":"markdown","metadata":{},"source":["### Data Loaders"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2025-04-07T18:01:45.439557Z","iopub.status.busy":"2025-04-07T18:01:45.439196Z","iopub.status.idle":"2025-04-07T18:01:54.065511Z","shell.execute_reply":"2025-04-07T18:01:54.064719Z","shell.execute_reply.started":"2025-04-07T18:01:45.439519Z"},"trusted":true},"outputs":[],"source":["# Creating data loader for both train and validation\n","train_loader = dataset.create_dataloader(train_data, batch_size=2, max_length=context_len, stride=context_len,\n","                                         drop_last=True, shuffle=True, num_workers=0)\n","\n","val_loader = dataset.create_dataloader(val_data, batch_size=2, max_length=context_len, stride=context_len,\n","                                        drop_last=False, shuffle=False, num_workers=0)"]},{"cell_type":"markdown","metadata":{},"source":["### Model Defination"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2025-04-07T18:14:42.168095Z","iopub.status.busy":"2025-04-07T18:14:42.167628Z","iopub.status.idle":"2025-04-07T18:14:42.175106Z","shell.execute_reply":"2025-04-07T18:14:42.173949Z","shell.execute_reply.started":"2025-04-07T18:14:42.168053Z"},"trusted":true},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2025-04-07T18:16:54.831578Z","iopub.status.busy":"2025-04-07T18:16:54.831271Z","iopub.status.idle":"2025-04-07T18:16:58.968003Z","shell.execute_reply":"2025-04-07T18:16:58.967023Z","shell.execute_reply.started":"2025-04-07T18:16:54.831556Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading Model weights from /kaggle/working/model_and_optimizer.pth\n","##============== Model Summary =========================##\n","# Total number of parameters: 163,009,536\n","# Token embedding layer shape: torch.Size([50257, 768])\n","# Output layer shape: torch.Size([50257, 768])\n","# Number of trainable parameters considering weight tying: 124,412,160\n","# Total size of the model: 621.83 MB\n","##======================================================##\n","Model Defined\n"]}],"source":["model_llm = model.LLMModel(config_train)\n","model_llm = model.load_model(model_llm, model_filepath) # Resuming training by loading previously trained model\n","model.print_model_information(model_llm)\n","\n","if torch.cuda.device_count() > 1:\n","    model_llm = nn.DataParallel(model_llm)\n","\n","model_llm.to(device)                                    # Assigning GPU/CPU to model\n","print(\"Model Defined\")"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2025-04-07T18:17:01.546132Z","iopub.status.busy":"2025-04-07T18:17:01.545852Z","iopub.status.idle":"2025-04-07T18:17:01.552763Z","shell.execute_reply":"2025-04-07T18:17:01.552006Z","shell.execute_reply.started":"2025-04-07T18:17:01.546112Z"},"trusted":true},"outputs":[],"source":["optimizer = torch.optim.AdamW(model_llm.parameters(), lr=0.0004, weight_decay=0.1)"]},{"cell_type":"markdown","metadata":{},"source":["### Lets train"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2025-04-07T18:17:06.660405Z","iopub.status.busy":"2025-04-07T18:17:06.660050Z","iopub.status.idle":"2025-04-07T18:33:01.155502Z","shell.execute_reply":"2025-04-07T18:33:01.154255Z","shell.execute_reply.started":"2025-04-07T18:17:06.660379Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Ep 1 (Step 000000): Train loss 6.976, Val loss 6.313\n","Ep 1 (Step 000100): Train loss 5.460, Val loss 6.158\n","Ep 1 (Step 000200): Train loss 5.695, Val loss 5.999\n","Ep 1 (Step 000300): Train loss 5.530, Val loss 6.000\n","Ep 1 (Step 000400): Train loss 4.918, Val loss 5.950\n","Ep 1 (Step 000500): Train loss 5.149, Val loss 5.890\n","Ep 1 (Step 000600): Train loss 5.122, Val loss 5.844\n","Ep 1 (Step 000700): Train loss 5.105, Val loss 5.783\n","Ep 1 (Step 000800): Train loss 4.854, Val loss 5.763\n","Ep 1 (Step 000900): Train loss 4.598, Val loss 5.748\n","Ep 1 (Step 001000): Train loss 4.802, Val loss 5.760\n","Ep 1 (Step 001100): Train loss 4.816, Val loss 5.702\n","Ep 1 (Step 001200): Train loss 4.456, Val loss 5.632\n","Ep 1 (Step 001300): Train loss 4.798, Val loss 5.679\n","Ep 1 (Step 001400): Train loss 4.733, Val loss 5.659\n","Ep 1 (Step 001500): Train loss 4.293, Val loss 5.635\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n","\u001b[0;32m/kaggle/working/llm/bhasa/training.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter, start_context, tokenizer)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minput_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             loss = calc_loss_batch(\n\u001b[0m\u001b[1;32m    138\u001b[0m                 \u001b[0minput_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             )\n","\u001b[0;32m/kaggle/working/llm/bhasa/training.py\u001b[0m in \u001b[0;36mcalc_loss_batch\u001b[0;34m(input_batch, target_batch, model, device)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0minput_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mtarget_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     loss = torch.nn.functional.cross_entropy(\n\u001b[1;32m     36\u001b[0m         \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodule_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     ) -> List[Any]:\n\u001b[0;32m--> 212\u001b[0;31m         return parallel_apply(\n\u001b[0m\u001b[1;32m    213\u001b[0m             \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstreams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["%%time\n","\n","# Training LLM model from scratch\n","train_losses, val_losses, tokens_seen = training.train_model(model_llm, \n","                                                             train_loader, \n","                                                             val_loader, \n","                                                             optimizer, \n","                                                             device, \n","                                                             num_epochs=2, \n","                                                             eval_freq=100, \n","                                                             eval_iter=5,\n","                                                             start_context=\"Every effort moves you\", \n","                                                             tokenizer=tokenizer)\n","model.save_model(model_llm, optimizer, model_filepath)"]},{"cell_type":"markdown","metadata":{},"source":["### Plot Results Train vs Validation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2025-04-07T18:06:38.709163Z","iopub.status.idle":"2025-04-07T18:06:38.709511Z","shell.execute_reply":"2025-04-07T18:06:38.709354Z"},"trusted":true},"outputs":[],"source":["epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n","training.plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":232483210,"sourceType":"kernelVersion"}],"dockerImageVersionId":30919,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":4}
