{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":232483210,"sourceType":"kernelVersion"}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!rm -rf llm\n!git clone https://github.com/pankajr141/llm.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:00:53.542285Z","iopub.execute_input":"2025-04-07T18:00:53.542598Z","iopub.status.idle":"2025-04-07T18:00:54.227123Z","shell.execute_reply.started":"2025-04-07T18:00:53.542557Z","shell.execute_reply":"2025-04-07T18:00:54.226052Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'llm'...\nremote: Enumerating objects: 78, done.\u001b[K\nremote: Counting objects: 100% (78/78), done.\u001b[K\nremote: Compressing objects: 100% (54/54), done.\u001b[K\nremote: Total 78 (delta 36), reused 58 (delta 19), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (78/78), 47.22 KiB | 6.75 MiB/s, done.\nResolving deltas: 100% (36/36), done.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Existing Model to be used for retraining","metadata":{}},{"cell_type":"code","source":"!ls /kaggle/input/llm-bhasa","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:08:39.888405Z","iopub.execute_input":"2025-04-07T18:08:39.888766Z","iopub.status.idle":"2025-04-07T18:08:40.068224Z","shell.execute_reply.started":"2025-04-07T18:08:39.888738Z","shell.execute_reply":"2025-04-07T18:08:40.066883Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"# LLM Training","metadata":{}},{"cell_type":"markdown","source":"## Training - Direct through library","metadata":{}},{"cell_type":"code","source":"%%time\n\nfrom llm.bhasa import training\nmodel_filepath=\"/kaggle/working/model_and_optimizer.pth\"\n# training.train(num_epochs=1, eval_freq=100)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:00:54.228430Z","iopub.execute_input":"2025-04-07T18:00:54.228824Z","iopub.status.idle":"2025-04-07T18:00:56.379651Z","shell.execute_reply.started":"2025-04-07T18:00:54.228787Z","shell.execute_reply":"2025-04-07T18:00:56.378904Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## Training - Lets break down\n\nBelow we will break above single line function into building blocks to have more fine grain control","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nfrom llm.bhasa import data\nfrom llm.bhasa import config\nfrom llm.bhasa import model\nfrom llm.bhasa import training\nfrom llm.bhasa import generator\nfrom llm.bhasa import data, dataset\nfrom llm.bhasa import tokenizer as tokenizer_lib","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:15:30.840503Z","iopub.execute_input":"2025-04-07T18:15:30.840844Z","iopub.status.idle":"2025-04-07T18:15:30.845570Z","shell.execute_reply.started":"2025-04-07T18:15:30.840816Z","shell.execute_reply":"2025-04-07T18:15:30.844508Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"model_filepath = \"/kaggle/working/model_and_optimizer.pth\"\nconfig_train = config.GPT_CONFIG_124M\ncontext_len = config_train['context_length']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:00:56.389508Z","iopub.execute_input":"2025-04-07T18:00:56.389854Z","iopub.status.idle":"2025-04-07T18:00:56.403995Z","shell.execute_reply.started":"2025-04-07T18:00:56.389816Z","shell.execute_reply":"2025-04-07T18:00:56.402988Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"### Download data","metadata":{}},{"cell_type":"code","source":"%%time\n\ngutenberg_book_ids = range(100)\nfilepaths = data.download_sample_text(gutenberg_book_ids=gutenberg_book_ids, verbose=False)\ntextdata = data.read_filepaths(filepaths)\n\nprint(f\"Total Downloaded Books: {len(os.listdir('gutenberg_books'))}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:07:02.429950Z","iopub.execute_input":"2025-04-07T18:07:02.430243Z","iopub.status.idle":"2025-04-07T18:07:45.874147Z","shell.execute_reply.started":"2025-04-07T18:07:02.430221Z","shell.execute_reply":"2025-04-07T18:07:45.873204Z"}},"outputs":[{"name":"stdout","text":"Total Downloaded Books: 72\nCPU times: user 709 ms, sys: 247 ms, total: 956 ms\nWall time: 43.4 s\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"from llm.bhasa import tokenizer as tokenizer_lib\ntokenizer = tokenizer_lib.get_tokenizer()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:01:40.340047Z","iopub.execute_input":"2025-04-07T18:01:40.340333Z","iopub.status.idle":"2025-04-07T18:01:40.343838Z","shell.execute_reply.started":"2025-04-07T18:01:40.340307Z","shell.execute_reply":"2025-04-07T18:01:40.343204Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"total_characters = len(textdata)                # Number of characters in textdata\ntotal_tokens = len(tokenizer.encode(textdata))  # Convert/Encode textdata -> tokens to be passed to LLM\nprint(f\"Characters: {total_characters}\\nTokens: {total_tokens}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:01:40.344792Z","iopub.execute_input":"2025-04-07T18:01:40.345085Z","iopub.status.idle":"2025-04-07T18:01:45.362874Z","shell.execute_reply.started":"2025-04-07T18:01:40.345054Z","shell.execute_reply":"2025-04-07T18:01:45.361794Z"}},"outputs":[{"name":"stdout","text":"Characters: 36845989\nTokens: 10057729\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"train_data, val_data = training.split_data(textdata, train_ratio=0.70)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:01:45.363712Z","iopub.execute_input":"2025-04-07T18:01:45.363957Z","iopub.status.idle":"2025-04-07T18:01:45.437999Z","shell.execute_reply.started":"2025-04-07T18:01:45.363935Z","shell.execute_reply":"2025-04-07T18:01:45.436901Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"### Data Loaders","metadata":{}},{"cell_type":"code","source":"# Creating data loader for both train and validation\ntrain_loader = dataset.create_dataloader(train_data, batch_size=2, max_length=context_len, stride=context_len,\n                                         drop_last=True, shuffle=True, num_workers=0)\n\nval_loader = dataset.create_dataloader(val_data, batch_size=2, max_length=context_len, stride=context_len,\n                                        drop_last=False, shuffle=False, num_workers=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:01:45.439196Z","iopub.execute_input":"2025-04-07T18:01:45.439557Z","iopub.status.idle":"2025-04-07T18:01:54.065511Z","shell.execute_reply.started":"2025-04-07T18:01:45.439519Z","shell.execute_reply":"2025-04-07T18:01:54.064719Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"### Model Defination","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:14:42.167628Z","iopub.execute_input":"2025-04-07T18:14:42.168095Z","iopub.status.idle":"2025-04-07T18:14:42.175106Z","shell.execute_reply.started":"2025-04-07T18:14:42.168053Z","shell.execute_reply":"2025-04-07T18:14:42.173949Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"model_llm = model.LLMModel(config_train)\nmodel_llm = model.load_model(model_llm, model_filepath) # Resuming training by loading previously trained model\nmodel.print_model_information(model_llm)\n\nif torch.cuda.device_count() > 1:\n    model_llm = nn.DataParallel(model_llm)\n\nmodel_llm.to(device)                                    # Assigning GPU/CPU to model\nprint(\"Model Defined\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:16:54.831271Z","iopub.execute_input":"2025-04-07T18:16:54.831578Z","iopub.status.idle":"2025-04-07T18:16:58.968003Z","shell.execute_reply.started":"2025-04-07T18:16:54.831556Z","shell.execute_reply":"2025-04-07T18:16:58.967023Z"}},"outputs":[{"name":"stdout","text":"Loading Model weights from /kaggle/working/model_and_optimizer.pth\n##============== Model Summary =========================##\n# Total number of parameters: 163,009,536\n# Token embedding layer shape: torch.Size([50257, 768])\n# Output layer shape: torch.Size([50257, 768])\n# Number of trainable parameters considering weight tying: 124,412,160\n# Total size of the model: 621.83 MB\n##======================================================##\nModel Defined\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(model_llm.parameters(), lr=0.0004, weight_decay=0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:17:01.545852Z","iopub.execute_input":"2025-04-07T18:17:01.546132Z","iopub.status.idle":"2025-04-07T18:17:01.552763Z","shell.execute_reply.started":"2025-04-07T18:17:01.546112Z","shell.execute_reply":"2025-04-07T18:17:01.552006Z"}},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":"### Lets train","metadata":{}},{"cell_type":"code","source":"%%time\n\n# Training LLM model from scratch\ntrain_losses, val_losses, tokens_seen = training.train_model(model_llm, \n                                                             train_loader, \n                                                             val_loader, \n                                                             optimizer, \n                                                             device, \n                                                             num_epochs=2, \n                                                             eval_freq=100, \n                                                             eval_iter=5,\n                                                             start_context=\"Every effort moves you\", \n                                                             tokenizer=tokenizer)\nmodel.save_model(model_llm, optimizer, model_filepath)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:17:06.660050Z","iopub.execute_input":"2025-04-07T18:17:06.660405Z","iopub.status.idle":"2025-04-07T18:33:01.155502Z","shell.execute_reply.started":"2025-04-07T18:17:06.660379Z","shell.execute_reply":"2025-04-07T18:33:01.154255Z"}},"outputs":[{"name":"stdout","text":"Ep 1 (Step 000000): Train loss 6.976, Val loss 6.313\nEp 1 (Step 000100): Train loss 5.460, Val loss 6.158\nEp 1 (Step 000200): Train loss 5.695, Val loss 5.999\nEp 1 (Step 000300): Train loss 5.530, Val loss 6.000\nEp 1 (Step 000400): Train loss 4.918, Val loss 5.950\nEp 1 (Step 000500): Train loss 5.149, Val loss 5.890\nEp 1 (Step 000600): Train loss 5.122, Val loss 5.844\nEp 1 (Step 000700): Train loss 5.105, Val loss 5.783\nEp 1 (Step 000800): Train loss 4.854, Val loss 5.763\nEp 1 (Step 000900): Train loss 4.598, Val loss 5.748\nEp 1 (Step 001000): Train loss 4.802, Val loss 5.760\nEp 1 (Step 001100): Train loss 4.816, Val loss 5.702\nEp 1 (Step 001200): Train loss 4.456, Val loss 5.632\nEp 1 (Step 001300): Train loss 4.798, Val loss 5.679\nEp 1 (Step 001400): Train loss 4.733, Val loss 5.659\nEp 1 (Step 001500): Train loss 4.293, Val loss 5.635\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n","\u001b[0;32m/kaggle/working/llm/bhasa/training.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter, start_context, tokenizer)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minput_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             loss = calc_loss_batch(\n\u001b[0m\u001b[1;32m    138\u001b[0m                 \u001b[0minput_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             )\n","\u001b[0;32m/kaggle/working/llm/bhasa/training.py\u001b[0m in \u001b[0;36mcalc_loss_batch\u001b[0;34m(input_batch, target_batch, model, device)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0minput_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mtarget_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     loss = torch.nn.functional.cross_entropy(\n\u001b[1;32m     36\u001b[0m         \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodule_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     ) -> List[Any]:\n\u001b[0;32m--> 212\u001b[0;31m         return parallel_apply(\n\u001b[0m\u001b[1;32m    213\u001b[0m             \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstreams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":36},{"cell_type":"markdown","source":"### Plot Results Train vs Validation","metadata":{}},{"cell_type":"code","source":"epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\ntraining.plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:06:38.709163Z","iopub.status.idle":"2025-04-07T18:06:38.709511Z","shell.execute_reply":"2025-04-07T18:06:38.709354Z"}},"outputs":[],"execution_count":null}]}